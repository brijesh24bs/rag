{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXSI6a7YlWyE",
        "outputId": "bd03dac7-b017-40be-c80a-6581ccfdd2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.1.3-py3-none-any.whl (11 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.5.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.45 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.1.48)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (0.1.52)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain-groq) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain-groq) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (3.10.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain-groq) (2.0.7)\n",
            "Installing collected packages: h11, httpcore, httpx, groq, langchain-groq\n",
            "Successfully installed groq-0.5.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-groq-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install langchain-groq\n",
        "!pip install chromadb #vector database"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf1 = \"/content/deep_work.pdf\"\n",
        "\n",
        "pdf2 = \"https://arxiv.org/pdf/2005.11401.pdf\"\n",
        "\n",
        "loaders = [\n",
        "  # Duplicate documents on purpose - messy data\n",
        "  PyPDFLoader(pdf1),\n",
        "  PyPDFLoader(pdf1),\n",
        "  PyPDFLoader(pdf2),\n",
        "]\n",
        "\n",
        "docs = []\n",
        "for i, loader in enumerate(loaders):\n",
        "  pages = loader.load()\n",
        "  print(f\"For doc = {i}, number of pages: {len(pages)}\")\n",
        "  docs.extend(loader.load())\n",
        "\n",
        "print(f\"Length of docs {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBLANs56ovHQ",
        "outputId": "f91a9ade-010f-496a-e369-182af9cd29b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For doc = 0, number of pages: 8\n",
            "For doc = 1, number of pages: 8\n",
            "For doc = 2, number of pages: 19\n",
            " length of docs 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking documents\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "  chunk_size = 1500,\n",
        "  chunk_overlap = 150,\n",
        "  separators=['\\n\\n','. ']\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOcRs8q6pm4n",
        "outputId": "9433ea56-bb29-4354-dafc-982f8aaba0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_community.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings\n",
        "\n",
        "embedding = HuggingFaceInferenceAPIEmbeddings(\n",
        "    api_key=userdata.get('hf_api'), model_name=\"sentence-transformers/all-MiniLM-l6-v2\"  ##need to use this model due to size constraint in\n",
        "    #hugging face serverless inference api\n",
        ")"
      ],
      "metadata": {
        "id": "RvmkOnHdqTCQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = './chroma'\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "  documents=chunks,\n",
        "  embedding=embedding,\n",
        "  persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "EFhlNdyi2-v7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is a deep work\"\n",
        "\n",
        "docs_similarity_search = vectordb.similarity_search(question, k=3)\n",
        "\n",
        "for doc in docs_similarity_search:\n",
        "  print(doc.page_content[:200], f\"==> metadata = {doc.metadata}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWthwUJV7IKn",
        "outputId": "4f88a8f1-a9d1-4e0a-f5ca-d93b5d591472"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". This kind of work\n",
            "means we don't create anything of value. So why is it that we gravitate\n",
            "towards shallow work?\n",
            "The truth is that shallow work is easy, and deep work is difficult.\n",
            "Furthermore, shall ==> metadata = {'page': 1, 'source': '/content/deep_work.pdf'}\n",
            ". This kind of work\n",
            "means we don't create anything of value. So why is it that we gravitate\n",
            "towards shallow work?\n",
            "The truth is that shallow work is easy, and deep work is difficult.\n",
            "Furthermore, shall ==> metadata = {'page': 1, 'source': '/content/deep_work.pdf'}\n",
            "All of the best, and most creative work, emerges from a state of clear\n",
            "focus and careful attention. So, perhaps deep work, along with restorative\n",
            "rest is just the antidote we need. Deep Work is a guid ==> metadata = {'page': 7, 'source': '/content/deep_work.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    api_key=userdata.get('groq_api'),\n",
        "    temperature=0,\n",
        "    model = 'Llama3-8b-8192'\n",
        ")"
      ],
      "metadata": {
        "id": "kdJjc4_27Kmx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieval qa chains\n",
        "# 1- Base chain: Include the whole context in the query to the LLM\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=vectordb.as_retriever(),\n",
        "  return_source_documents=True,\n",
        ")"
      ],
      "metadata": {
        "id": "mTKxFqi5FGk-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is a deep work\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(f\"Answer:\\n {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-3xIUZXFfGt",
        "outputId": "00831676-4b22-4a15-ef55-1fd306d4faee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " According to the provided text, deep work refers to a type of work that requires clear focus and careful attention. It is described as difficult to do because it requires uninterrupted time and dedication to one's craft. Deep work is contrasted with shallow work, which is easy and deceptive, disguising itself as productivity but adding little value to one's work output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get source documents\n",
        "for doc in result['source_documents']:\n",
        "  print(doc.page_content[:200], f\"==> metadata = {doc.metadata}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKgwLWXQFh_m",
        "outputId": "6ff4a4dc-db48-4ca2-b552-af721b6c7cdf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". This kind of work\n",
            "means we don't create anything of value. So why is it that we gravitate\n",
            "towards shallow work?\n",
            "The truth is that shallow work is easy, and deep work is difficult.\n",
            "Furthermore, shall ==> metadata = {'page': 1, 'source': '/content/deep_work.pdf'}\n",
            "\n",
            ". This kind of work\n",
            "means we don't create anything of value. So why is it that we gravitate\n",
            "towards shallow work?\n",
            "The truth is that shallow work is easy, and deep work is difficult.\n",
            "Furthermore, shall ==> metadata = {'page': 1, 'source': '/content/deep_work.pdf'}\n",
            "\n",
            "All of the best, and most creative work, emerges from a state of clear\n",
            "focus and careful attention. So, perhaps deep work, along with restorative\n",
            "rest is just the antidote we need. Deep Work is a guid ==> metadata = {'page': 7, 'source': '/content/deep_work.pdf'}\n",
            "\n",
            "All of the best, and most creative work, emerges from a state of clear\n",
            "focus and careful attention. So, perhaps deep work, along with restorative\n",
            "rest is just the antidote we need. Deep Work is a guid ==> metadata = {'page': 7, 'source': '/content/deep_work.pdf'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MMR retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=vectordb.as_retriever(search_type = \"mmr\"),\n",
        "  return_source_documents=True,\n",
        ")\n",
        "\n",
        "question = \"What is a deep work\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(f\"Answer:\\n {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBYfdy6mFvnp",
        "outputId": "6d540408-8bf8-49ed-ba9e-08fbdd1bdf06"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " According to the provided text, deep work refers to a state of clear focus and careful attention, where one dedicates uninterrupted time to their craft. It is described as difficult to achieve because it requires spending time without distractions, which is hard to do. Deep work is contrasted with shallow work, which is easy to do but adds little value to one's work output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-Map-reduce chain: Each individual chunk is sent to the LLM, to get a base answer. Then those answers are composed\n",
        "# to get the final answer\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=vectordb.as_retriever(),\n",
        "  chain_type=\"map_reduce\"\n",
        ")\n",
        "\n",
        "question = \"What is a deep work?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(f\"Answer:\\n {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbxbQW2rF7TP",
        "outputId": "695bc77d-d32b-4fd0-e670-245e1e4bd2a8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " According to the provided text, \"Deep work\" is difficult because it's hard to spend uninterrupted time routinely dedicated to your craft.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-refine chain: each chunk is passed to llm composed with the answer from the previous llm\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=vectordb.as_retriever(),\n",
        "  chain_type=\"refine\"\n",
        ")\n",
        "\n",
        "question = \"What is a deep work\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(f\"Answer:\\n {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU-S8Ig1GXTn",
        "outputId": "d1d77ef9-d313-4a45-9242-41370073b957"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " With the additional context, I can refine the original answer to provide a more accurate definition of deep work.\n",
            "\n",
            "Deep work refers to a state of clear focus and careful attention, where one can eliminate distractions and improve overall focus. It is a guide that shows us that we can take back control of our time, eliminate distractions, and improve our overall focus. In essence, deep work is the antidote to the constant distractions and noise that can hinder productivity and creativity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 - Map rerank: Each chunk is passed to the LLM and the answer from the each chunk is ranked. Chunk with\n",
        "# higher rank is the result\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=vectordb.as_retriever(),\n",
        "  chain_type=\"map_rerank\"\n",
        ")\n",
        "question = \"What is a deep work?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(f\"Answer:\\n {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmZB6w0WG-yj",
        "outputId": "20bcf156-0580-44e3-c8fd-e2a8929157f7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:367: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " Helpful Answer: Deep work is difficult because it's hard to spend uninterrupted time routinely dedicated to your craft.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using custom prompt template\n",
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\"Use the provided context to respond to the question posed at the end. If you're unsure of the answer, please feel free to acknowledge that you don't know rather than attempting to provide a fabricated response.\n",
        "Please provide a brief and concise response.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "QA_CHAIN_PROMPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KZBLHZcHZPd",
        "outputId": "f1233586-418c-463a-9550-0f8ca70337fd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'question'], template=\"Use the provided context to respond to the question posed at the end. If you're unsure of the answer, please feel free to acknowledge that you don't know rather than attempting to provide a fabricated response.\\nPlease provide a brief and concise response.\\n{context}\\nQuestion: {question}\\nHelpful Answer:\")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=vectordb.as_retriever(),\n",
        "  return_source_documents=True,\n",
        "  chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n",
        "\n",
        "question = \"What is a deep work\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(f\"Answer:\\n {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMKtYFjrHzXY",
        "outputId": "6928244c-b30a-40cc-9328-3af299d37f64"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " According to the provided context, a deep work is a type of work that requires uninterrupted time and focus, allowing individuals to dedicate themselves to their craft. It is described as difficult to achieve due to the ease of shallow work and the distractions that come with it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTGq-dGhH88D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}